{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPxLf+eT/zxy83rQo8OIxD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mobeenahmedmehr/Mobeen_Ahmed/blob/main/Project_03_LangChain_Function_Tool_Calling_%5Btranslater%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚öì Installing the Required Library\n",
        "\n"
      ],
      "metadata": {
        "id": "8OC6TnzAnUcz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnFtvsAg8z_6"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ñ∂ **What it does**:\n",
        " This line installs the langchain-google-genai library, which allows us to use Google's Gemini AI models (like Gemini 1.5 Flash) in our code.\n",
        "\n",
        "## üé° **Why it's needed**:\n",
        " Without this library, we can't use the tools and functions provided by LangChain to interact with Google's AI models."
      ],
      "metadata": {
        "id": "-D7LAxusnz2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Importing Required Modules"
      ],
      "metadata": {
        "id": "C--1tMLLoLAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import initialize_agent, AgentType"
      ],
      "metadata": {
        "id": "AtefNZO6wsP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ñ∂ **What it does**:\n",
        "These lines import the necessary tools and libraries:\n",
        "\n",
        "**ChatGoogleGenerativeAI**: This is the class that lets us interact with Google's Gemini AI models.\n",
        "\n",
        "**tool**: This is a decorator that helps us create custom tools (like summarization or translation).\n",
        "\n",
        "**initialize_agent and AgentType**: These are used to create an AI agent that can use multiple tools.\n",
        "\n",
        "**os and userdata**: These are used to securely access the API key for Google's Gemini AI."
      ],
      "metadata": {
        "id": "tPX48DUSoWTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Setting Up the API Key"
      ],
      "metadata": {
        "id": "wNm_HYw5oZLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "Gemini_API_KEY = userdata.get('Gemini_API_KEY')"
      ],
      "metadata": {
        "id": "pX2ry0rrIUSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This line retrieves the API key for Google's Gemini AI from Google Colab's secure storage.\n",
        "\n",
        "##üé° **Why it's needed**:\n",
        "ü•Å The API key is required to authenticate and use Google's AI services. Without it, the code won't work."
      ],
      "metadata": {
        "id": "pxC2SGSPoZDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Initializing the AI Model"
      ],
      "metadata": {
        "id": "52QMiXchorvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key= Gemini_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "YNO2pCF1IkPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This line initializes the AI model (gemini-1.5-flash) using the API key.\n",
        "\n",
        "##üé° **Why it's needed**:\n",
        "ü•Å This is the core of the program. It sets up the AI model that will perform tasks like summarization and translation."
      ],
      "metadata": {
        "id": "b3MfbYdfowEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Creating a Summarization Tool"
      ],
      "metadata": {
        "id": "eZ1DHAoyoz1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def summarize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Summarize a given text.\n",
        "    Input: A string of text (e.g., an article or paragraph).\n",
        "    Output: A concise summary of the text.\n",
        "    \"\"\"\n",
        "    prompt = f\"Summarize the following text in a concise manner:\\n\\n{text}\"\n",
        "    return llm.predict(prompt)"
      ],
      "metadata": {
        "id": "OoZU2dSSI3iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This defines a tool called summarize_text that takes a long text as input and returns a shorter summary.\n",
        "\n",
        "##üî• **How it works**:\n",
        "\n",
        "ü•Å The **@tool decorator** tells LangChain that this function is a tool the AI can use.\n",
        "\n",
        "ü•Å The **functio**n creates a prompt asking the AI to summarize the text.\n",
        "\n",
        "ü•Å The **llm.predict(prompt)** sends the prompt to the AI model and returns the summary."
      ],
      "metadata": {
        "id": "7bbEpcUao5t1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Creating a Translation Tool"
      ],
      "metadata": {
        "id": "6cFRRbtZpB8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def translate_text(text: str, target_language: str) -> str:\n",
        "    \"\"\"\n",
        "    Translate text into a specified target language.\n",
        "    Input: Text and the target language (e.g., 'French', 'Spanish').\n",
        "    Output: Translated text.\n",
        "    \"\"\"\n",
        "    prompt = f\"Translate the following text into {target_language}:\\n\\n{text}\"\n",
        "    return llm.predict(prompt)"
      ],
      "metadata": {
        "id": "VRn0NDaNI9Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This defines a tool called translate_text that takes text and a target language (like Urdu or French) as input and returns the translated text.\n",
        "\n",
        "##üî• **How it works**:\n",
        "\n",
        "ü•Å Similar to the summarization tool, it uses the **@tool decorator**.\n",
        "\n",
        "ü•Å It creates a prompt asking the **AI to translate the text** into the specified language.\n",
        "\n",
        "ü•Å The **llm.predict(prompt)** sends the prompt to the AI model and returns the translation."
      ],
      "metadata": {
        "id": "XJlYNyXUpJr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Setting Up the Tools"
      ],
      "metadata": {
        "id": "5z5kQtwBpL5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [summarize_text, translate_text]"
      ],
      "metadata": {
        "id": "N3rQ3V3NJB8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This line creates a list of tools (summarization and translation) that the AI agent can use.\n",
        "\n",
        "##üé° **Why it's needed**:\n",
        "ü•Å The **AI agent** needs to know which tools are available to perform tasks."
      ],
      "metadata": {
        "id": "wzzg0UsKpQOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Initializing the AI Agent"
      ],
      "metadata": {
        "id": "ZSBJ6RaIpUgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "Dd1OPNtgJIKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This line creates an AI agent that can use the tools we defined earlier.\n",
        "\n",
        "##üî• **How it works**:\n",
        "\n",
        "ü•Å **tools=tools**: Tells the agent which tools it can use.\n",
        "\n",
        "ü•Å **llm=llm**: Specifies the AI model to use (Gemini 1.5 Flash).\n",
        "\n",
        "ü•Å **agent=AgentType.OPENAI_FUNCTIONS**: Specifies the type of agent (this is a pre-defined agent type that works well with function-based tools).\n",
        "\n",
        "ü•Å **verbose=True**: Makes the agent print detailed logs so we can see what it's doing."
      ],
      "metadata": {
        "id": "xQxjN51ppbcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Testing the Summarization Tool"
      ],
      "metadata": {
        "id": "TgRwDg1tphFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Summarization Example\n",
        "    text_to_summarize = (\n",
        "        \"Artificial intelligence is the simulation of human intelligence processes by machines, \"\n",
        "        \"especially computer systems. Specific applications of AI include expert systems, natural \"\n",
        "        \"language processing, speech recognition, and machine vision.\"\n",
        "    )\n",
        "    print(\"Testing Summarization:\")\n",
        "    summary = agent.run(f\"Summarize this: {text_to_summarize}\")\n",
        "    print(f\"Summary:\\n{summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnRHOA5RJMQz",
        "outputId": "f7879e62-0921-4fda-91a7-ac9fa7095211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Summarization:\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-0de1a19eaa25>:9: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  summary = agent.run(f\"Summarize this: {text_to_summarize}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `summarize_text` with `{'text': 'Artificial intelligence is the simulation of human intelligence processes by machines, especially computer systems. Specific applications of AI include expert systems, natural language processing, speech recognition, and machine vision.'}`\n",
            "\n",
            "\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-dbd07f700a2d>:9: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  return llm.predict(prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mAI simulates human intelligence in machines, using applications like expert systems and natural language processing.\u001b[0m\u001b[32;1m\u001b[1;3mAI simulates human intelligence in machines, using applications like expert systems and natural language processing.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Summary:\n",
            "AI simulates human intelligence in machines, using applications like expert systems and natural language processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This tests the summarization tool by giving it a paragraph about artificial intelligence and asking it to summarize it.\n",
        "\n",
        "##üî• **How it works**:\n",
        "\n",
        "ü•Å The **agent.run()** function sends the task to the AI agent.\n",
        "\n",
        "ü•Å The **agent** uses the summarize_text tool to generate a summary.\n",
        "\n",
        "ü•Å The summary is printed to the screen."
      ],
      "metadata": {
        "id": "NeVBtfALpnIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Testing the Translation Tool"
      ],
      "metadata": {
        "id": "Eoh9kJAvpr33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_translate = \"What\"\n",
        "target_language = \"Urdu\"\n",
        "print(\"\\nTesting Translation:\")\n",
        "translation = agent.run(f\"Translate this text: {text_to_translate} into {target_language}\")\n",
        "print(f\"Translation:\\n{translation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20hdJxHBLkdv",
        "outputId": "d645f432-6b3e-4416-a3e3-b0a5a4cdc42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Translation:\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `translate_text` with `{'text': 'What', 'target_language': 'Urdu'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mThe Urdu translation of \"What\" depends on the context. Here are a few options:\n",
            "\n",
            "* **⁄©€åÿß (kyƒÅ):** This is the most common translation and is used for general questions.  For example, \"What is your name?\" would be \"ÿ¢Ÿæ ⁄©ÿß ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü\" (ƒÄp kƒÅ nƒÅm kyƒÅ hai?).\n",
            "\n",
            "* **⁄©ŸàŸÜ ÿ≥ÿß (kaun sƒÅ):** This translates to \"which\" and is used when choosing from a selection. For example, \"What color do you like?\" would be \"ÿ¢Ÿæ ⁄©Ÿà ⁄©ŸàŸÜ ÿ≥ÿß ÿ±ŸÜ⁄Ø Ÿæÿ≥ŸÜÿØ €Å€íÿü\" (ƒÄp ko kaun sƒÅ rang pasand hai?).\n",
            "\n",
            "* **⁄©ŸàŸÜ (kaun):** This translates to \"who\" and is used when asking about a person. For example, \"What is he?\" could be \"Ÿà€Å ⁄©ŸàŸÜ €Å€íÿü\" (Woh kaun hai?).\n",
            "\n",
            "\n",
            "Therefore, simply \"What?\" in isolation doesn't have a single perfect translation; the best choice depends entirely on the context of the sentence.\u001b[0m\u001b[32;1m\u001b[1;3mThe Urdu translation of \"What\" depends on the context.  The most common translation is ⁄©€åÿß (kyƒÅ), but other options exist depending on whether you are asking about a person, thing, or making a selection.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Translation:\n",
            "The Urdu translation of \"What\" depends on the context.  The most common translation is ⁄©€åÿß (kyƒÅ), but other options exist depending on whether you are asking about a person, thing, or making a selection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ñ∂ **What it does**:\n",
        "ü•Å This tests the translation tool by asking it to translate the word \"What\" into Urdu.\n",
        "\n",
        "##üî• **How it works**:\n",
        "\n",
        "ü•Å The **agent.run()** function sends the task to the AI agent.\n",
        "\n",
        "ü•Å The agent uses the translate_text tool to generate the translation.\n",
        "\n",
        "ü•Å The translation is printed to the screen."
      ],
      "metadata": {
        "id": "oZLVdNtzpwmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚è∞ Summary of the Code:\n",
        "‚úà Install the required library.\n",
        "\n",
        "‚úà Import necessary tools and modules.\n",
        "\n",
        "‚úà Set up the API key for Google's Gemini AI.\n",
        "\n",
        "‚úà Initialize the AI model.\n",
        "\n",
        "‚úà Create tools for summarization and translation.\n",
        "\n",
        "‚úà Set up the tools in a list.\n",
        "\n",
        "‚úà Initialize the AI agent.\n",
        "\n",
        "‚úà Test the summarization tool.\n",
        "\n",
        "‚úà Test the translation tool."
      ],
      "metadata": {
        "id": "Lq_9GNM_vyUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öõ **Key Points for Beginners**\n",
        "‚öæ **API Key**: Think of it as a password that allows your code to access Google's AI services.\n",
        "\n",
        "‚öæ **AI Model**: This is the \"brain\" that performs tasks like summarization and translation.\n",
        "\n",
        "‚öæ **Tools**: These are like apps that the AI can use to perform specific tasks.\n",
        "\n",
        "‚öæ **Agent**: This is the \"manager\" that decides which tool to use for a given task."
      ],
      "metadata": {
        "id": "NiAbqOA5wQ-u"
      }
    }
  ]
}